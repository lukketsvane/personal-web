---
title: "Handsporing for teiknspråk: Ei teknisk djupdykking"
description: "Implementasjon av eit ASL-attkjenningssystem ved bruk av maskinlæring og handsporing i nettlesaren"
date: "2024-12-02"
tags: ["teiknspråk", "maskinlæring", "yoha", "tensorflowjs", "handsporing"]
type: "teknisk"
category: "Maskinlæring"
---

I kjernen av moderne teiknspråkattkjenning ligg **handsporing** - ein teknologi som omset handrørsler til digitale koordinatar. La oss dykke ned i korleis me implementerer dette i nettlesaren.

## Teknisk arkitektur

> **Handsporing**: Ein maskinlæringsmodell som identifiserer 21 nøkkelpunkt på ei hand i sanntid.  
> *Kvart punkt er ein vektor i 3D-rommet (x, y, z).*

Implementasjonen vår brukar **TensorFlow.js** som grunnmur, med ein tilpassa nevral modell for handsporing:

```typescript
interface HandLandmark {
  x: number;  // x-koordinat i biletet
  y: number;  // y-koordinat i biletet
  z: number;  // djupne-estimat
}

class HandDetector {
  private model: tf.GraphModel;
  private readonly landmarkCount = 21;
  
  constructor() {
    this.model = await tf.loadGraphModel('/models/handpose');
  }

  async detectHand(frame: ImageData): Promise<HandLandmark[]> {
    const tensor = tf.browser.fromPixels(frame)
      .expandDims(0)
      .toFloat()
      .div(255);
    
    const prediction = await this.model.predict(tensor);
    return this.processLandmarks(prediction);
  }
}
```

## Attkjenning av teikn

For å kjenne att spesifikke handteikn, implementerer me ein **tilstandsmaskin** som analyserer handposisjonen over tid:

```typescript
interface HandPosition {
  landmarks: HandLandmark[];
  orientation: 'palm_up' | 'palm_down' | 'palm_side';
  motion: 'static' | 'dynamic';
}

class ASLDetector {
  private static readonly MOTION_THRESHOLD = 50; // pikslar
  private static readonly DETECTION_FRAMES = 10;
  private positionHistory: HandPosition[] = [];
  
  detectSign(position: HandPosition): ASLSign | null {
    this.positionHistory.push(position);
    this.positionHistory = this.positionHistory
      .slice(-this.DETECTION_FRAMES);
    
    if (this.isStaticSign(position)) {
      return this.classifyStaticSign(position);
    }
    
    return this.classifyDynamicSign(this.positionHistory);
  }
}
```

## Rørsleanalyse

For dynamiske teikn som 'J' og 'Z' må me analysere rørslene over tid:

```typescript
interface MotionPattern {
  path: Point[];
  duration: number;
  velocity: number;
}

private analyzeMotion(history: HandPosition[]): MotionPattern {
  const path = history.map(p => ({
    x: p.landmarks[8].x,  // peikefinger-tupp
    y: p.landmarks[8].y
  }));
  
  const duration = history.length * (1000 / 60); // ms
  const velocity = this.calculatePathVelocity(path);
  
  return { path, duration, velocity };
}
```

## Ytelseoptimalisering

> **SharedArrayBuffer**: Ein lågnivå-buffer som tillèt rask datadeling mellom trådar.  
> *Krev COOP/COEP-headers for sikker køyring.*

Me brukar **WebWorkers** for å flytte tunge utrekningar ut av hovudtråden:

```typescript
// worker.ts
self.onmessage = async (e: MessageEvent) => {
  const { frame, config } = e.data;
  const buffer = new SharedArrayBuffer(frame.width * frame.height * 4);
  const pixels = new Uint8ClampedArray(buffer);
  
  // Køyr modellen i arbeidstråden
  const landmarks = await detector.detect(pixels);
  self.postMessage({ landmarks }, [buffer]);
};
```

## Framtidsutsikter

Systemet vårt kan utvidast i fleire retningar:
- **WebGL-akselerasjon** for raskare inferens
- *Fleire-hands-støtte* for meir komplekse teikn
- Integrasjon med **WebAssembly** for nær-nativ ytelse
